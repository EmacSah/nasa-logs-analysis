# Analyse des Logs Web NASA avec Elasticsearch et Machine Learning

Ce projet dÃ©montre l'analyse de logs web historiques de la NASA (juillet 1995) Ã  l'aide d'Elasticsearch, Python et machine learning pour dÃ©tecter automatiquement les comportements suspects et les anomalies.

## ğŸ¯ Objectifs

- Traiter et analyser ~1.8 millions de lignes de logs web au format Common Log Format
- Concevoir un pipeline complet d'ingestion et d'indexation optimisÃ© pour Elasticsearch
- Explorer les patterns de trafic et identifier les comportements anormaux
- Construire un modÃ¨le prÃ©dictif pour la dÃ©tection automatique de comportements suspects
- IntÃ©grer le modÃ¨le ML dans Elasticsearch pour infÃ©rence en temps rÃ©el

## ğŸ“Š RÃ©sultats clÃ©s

- Identification des IPs et domaines les plus actifs (dominance des serveurs prodigy.com)
- DÃ©tection de comportements suspects (rush.internic.net avec 340 requÃªtes/heure)
- Analyse des erreurs HTTP (97% d'erreurs 404)
- ModÃ¨le de classification capable de dÃ©tecter les comportements anormaux avec 99.9% de prÃ©cision

  

## ğŸ› ï¸ Stack technique

- **Python 3.10+**: pandas, gzip, re, elasticsearch, tqdm, matplotlib, scikit-learn, xgboost
- **Elasticsearch 8.x**: indexation, requÃªtes, agrÃ©gations, ML
- **Google Colab/Drive**: exÃ©cution et stockage
- **Visualisation**: matplotlib, Kibana dashboards

## ğŸ“š Structure du projet

1. **Setup et configuration** 
   - Configuration de l'environnement
   - Connexion Elasticsearch

2. **Exploration et parsing** 
   - Analyse de la structure des logs
   - Parsing et nettoyage des donnÃ©es

3. **Indexation Elasticsearch** 
   - Conception du mapping
   - Indexation par lots optimisÃ©e

4. **Analyse et exploration** 
   - RequÃªtes simples et complexes
   - AgrÃ©gations temporelles et statistiques

5. **Machine Learning** (extension)
   - PrÃ©paration des donnÃ©es d'entraÃ®nement
   - ModÃ©lisation et Ã©valuation
   - IntÃ©gration Ã  Elasticsearch

## ğŸ“ˆ Visualisations

![Nombre de requÃªtes par heure](graphs/graph_requetes_par_heure.png)
![Top 10 IPs](graphs/top_ips.png)
![Distribution des erreurs HTTP](graphs/http_errors_distribution.png)

## ğŸ§  ModÃ¨le machine learning

Trois modÃ¨les ont Ã©tÃ© comparÃ©s pour la dÃ©tection de comportements suspects:
- Regression Logistique (baseline)
- Random Forest (performances parfaites sur ce dataset)
- XGBoost (excellentes performances, plus flexible)

Les caractÃ©ristiques utilisÃ©es incluent:
- Nombre de requÃªtes par IP/heure
- Proportion d'erreurs HTTP
- Nombre d'URLs uniques visitÃ©es
- Volume de donnÃ©es transfÃ©rÃ©es

## ğŸš€ Comment utiliser ce projet

### PrÃ©requis
- Python 3.10+
- Compte Elasticsearch Cloud ou cluster local
- Google Colab (recommandÃ©) ou Jupyter Notebook


## MÃ©triques de scalabilitÃ©
La conception modulaire permet une scalabilitÃ© horizontale:

- CapacitÃ© thÃ©orique de 100M+ logs/jour avec infrastructure appropriÃ©e
- AdaptabilitÃ© Ã  diffÃ©rents environnements (cloud, on-premise)
- Compatible avec orchestrateurs comme Kubernetes ou Airflow

## ApplicabilitÃ© en entreprise
Cette architecture peut Ãªtre directement adaptÃ©e pour:


ğŸ” **CybersÃ©curitÃ©**

- DÃ©tection d'intrusions en temps rÃ©el
- Identification de comportements anormaux
- Analyse forensique post-incident


ğŸ“ˆ **Monitoring d'infrastructure**

- Surveillance de performances applicatives
- DÃ©tection de dÃ©faillances systÃ¨me
- Analyse prÃ©dictive de problÃ¨mes potentiels


ğŸ’¡ **Analyse business**

- Monitoring de l'expÃ©rience utilisateur
- DÃ©tection de fraudes
- Analyse comportementale clients




 ## ğŸ“Conclusion technique

Ce projet dÃ©montre comment les principes d'architecture scalable et DevOps peuvent 
Ãªtre appliquÃ©s Ã  l'analyse de donnÃ©es volumineuses. Les techniques d'optimisation 
implÃ©mentÃ©es permettent de:

- Maximiser l'efficacitÃ© des ressources
- Automatiser l'ensemble du workflow de donnÃ©es
- Garantir la scalabilitÃ© pour des volumes bien supÃ©rieurs
- DÃ©ployer des modÃ¨les ML en production de faÃ§on fiable

L'architecture prÃ©sentÃ©e est transposable Ã  de nombreux cas d'usage d'entreprise 
nÃ©cessitant l'analyse de donnÃ©es volumineuses et la dÃ©tection d'anomalies en temps rÃ©el.

### Installation
```bash
pip install elasticsearch pandas tqdm matplotlib scikit-learn xgboost


